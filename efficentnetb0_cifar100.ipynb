{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR100 Based Image classification Model Retrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Train EfficientNet-B0 on CIFAR-100 using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required:\n",
    "import os\n",
    "import torch\n",
    "import platform\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import efficientnet_b0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters:\n",
    "epochs = 40\n",
    "LEARNING_RATE = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU Name: Orin\n",
      "CUDA Version: 12.6\n",
      "GPU Memory: 7.99 GB\n",
      "CPU: aarch64\n",
      "System: Linux 5.15.148-tegra\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Display GPU details if available\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    \n",
    "# Display CPU details\n",
    "print(f\"CPU: {platform.processor()}\")\n",
    "print(f\"System: {platform.system()} {platform.release()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load CIFAR-100 dataset\n",
    "trainset = torchvision.datasets.CIFAR100(root=\"./data\", train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "testset = torchvision.datasets.CIFAR100(root=\"./data\", train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained EfficientNet-B0\n",
    "model = efficientnet_b0(weights=\"IMAGENET1K_V1\")  \n",
    "model.classifier[1] = nn.Linear(1280, 100)  # Modify last layer for CIFAR-100 classes\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store training history\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []  # Added for validation loss\n",
    "val_accuracies = [] # Added for validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40, Loss: 2.9804, Accuracy: 26.73%\n",
      "Epoch 2/40, Loss: 1.9802, Accuracy: 46.03%\n",
      "Epoch 3/40, Loss: 1.6106, Accuracy: 54.69%\n",
      "Epoch 4/40, Loss: 1.4016, Accuracy: 59.75%\n",
      "Epoch 5/40, Loss: 1.2055, Accuracy: 64.54%\n",
      "Epoch 6/40, Loss: 1.0404, Accuracy: 68.87%\n",
      "Epoch 7/40, Loss: 0.9161, Accuracy: 72.03%\n",
      "Epoch 8/40, Loss: 0.7870, Accuracy: 75.69%\n",
      "Epoch 9/40, Loss: 0.7073, Accuracy: 78.00%\n",
      "Epoch 10/40, Loss: 0.6374, Accuracy: 79.81%\n",
      "Epoch 11/40, Loss: 0.5889, Accuracy: 81.32%\n",
      "Epoch 12/40, Loss: 0.5694, Accuracy: 82.07%\n",
      "Epoch 13/40, Loss: 0.5253, Accuracy: 83.33%\n",
      "Epoch 14/40, Loss: 0.4385, Accuracy: 85.97%\n",
      "Epoch 15/40, Loss: 0.4285, Accuracy: 86.14%\n",
      "Epoch 16/40, Loss: 0.3841, Accuracy: 87.60%\n",
      "Epoch 17/40, Loss: 0.3771, Accuracy: 87.83%\n",
      "Epoch 18/40, Loss: 0.3741, Accuracy: 88.05%\n",
      "Epoch 19/40, Loss: 0.3851, Accuracy: 87.68%\n",
      "Epoch 20/40, Loss: 0.3289, Accuracy: 89.40%\n",
      "Epoch 21/40, Loss: 0.2887, Accuracy: 90.65%\n",
      "Epoch 22/40, Loss: 0.3076, Accuracy: 90.28%\n",
      "Epoch 23/40, Loss: 0.2998, Accuracy: 90.34%\n",
      "Epoch 24/40, Loss: 0.2897, Accuracy: 90.73%\n",
      "Epoch 25/40, Loss: 0.2950, Accuracy: 90.70%\n",
      "Epoch 26/40, Loss: 0.2705, Accuracy: 91.38%\n",
      "Epoch 27/40, Loss: 0.2568, Accuracy: 91.86%\n",
      "Epoch 28/40, Loss: 0.2421, Accuracy: 92.15%\n",
      "Epoch 29/40, Loss: 0.2440, Accuracy: 92.27%\n",
      "Epoch 30/40, Loss: 0.2441, Accuracy: 92.36%\n",
      "Epoch 31/40, Loss: 0.2366, Accuracy: 92.54%\n",
      "Epoch 32/40, Loss: 0.2230, Accuracy: 92.73%\n",
      "Epoch 33/40, Loss: 0.2310, Accuracy: 92.60%\n",
      "Epoch 34/40, Loss: 0.2077, Accuracy: 93.44%\n",
      "Epoch 35/40, Loss: 0.2157, Accuracy: 93.19%\n",
      "Epoch 36/40, Loss: 0.2190, Accuracy: 93.13%\n",
      "Epoch 37/40, Loss: 0.2027, Accuracy: 93.66%\n",
      "Epoch 38/40, Loss: 0.1947, Accuracy: 93.82%\n",
      "Epoch 39/40, Loss: 0.1997, Accuracy: 93.72%\n",
      "Epoch 40/40, Loss: 0.1956, Accuracy: 93.89%\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in trainloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Compute accuracy\n",
    "        _, predicted = torch.max(outputs, 1)  # Get class with highest score\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(trainloader)\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracies.append(epoch_accuracy)\n",
    "\n",
    "\n",
    "    # Validation loop (add this part)\n",
    "    model.eval()  # Set to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad(): # No gradients during validation\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "    val_epoch_loss = val_loss / len(testloader)\n",
    "    val_epoch_accuracy = 100 * val_correct / val_total\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    val_accuracies.append(val_epoch_accuracy)\n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%, Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully as: /home/aman-nvidia/My_files/cv_projects/image_classification_webGUI/efficientnet_cifar100.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define base model path\n",
    "base_path = \"/home/aman-nvidia/My_files/cv_projects/image_classification_webGUI/efficientnet_cifar100\"\n",
    "file_extension = \".pth\"\n",
    "\n",
    "# Function to create filename with num_epochs AND counter (for saving)\n",
    "def get_model_path_save(base_path, file_extension, num_epochs):  # Renamed to clarify\n",
    "    epoch_path = f\"{base_path}_{num_epochs}\"\n",
    "\n",
    "    counter = 1\n",
    "    model_path = f\"{epoch_path}{file_extension}\"\n",
    "\n",
    "    while os.path.exists(model_path):\n",
    "        model_path = f\"{epoch_path}_{counter}{file_extension}\"\n",
    "        counter += 1\n",
    "\n",
    "    return model_path\n",
    "\n",
    "# Save the model\n",
    "model_path = get_model_path_save(base_path, file_extension, epochs)\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Model saved successfully as: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)  # Create a subplot for loss\n",
    "plt.plot(range(1, epochs + 1), train_losses, label=\"Train Loss\")\n",
    "plt.plot(range(1, epochs + 1), val_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training/Validation Loss\")\n",
    "\n",
    "plt.subplot(1, 2, 2)  # Create a subplot for accuracy\n",
    "plt.plot(range(1, epochs + 1), train_accuracies, label=\"Train Accuracy\")\n",
    "plt.plot(range(1, epochs + 1), val_accuracies, label=\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Training/Validation Accuracy\")\n",
    "\n",
    "plt.tight_layout() # Adjust subplot params so that subplots fit in to the figure area.\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
